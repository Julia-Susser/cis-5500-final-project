{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "collisions_df = pd.read_csv(\"../../input/collisions.csv\")\n",
    "geometry_df = gpd.read_file(\"../../input/taxi_zones/taxi_zones.shp\")\n",
    "collisions_df[\"crash_date\"] = pd.to_datetime(collisions_df[\"crash_date\"])\n",
    "collisions_df = collisions_df[collisions_df['crash_date'].dt.year == 2024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "parquet_files = glob.glob(\"../../input/yellow_taxi_data/*2024*.parquet\")\n",
    "all_dfs = []\n",
    "for file in parquet_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "taxi_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "taxi_df['tpep_pickup_datetime'] = pd.to_datetime(taxi_df['tpep_pickup_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41169720 entries, 0 to 41169719\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   PULocationID           int32         \n",
      " 7   DOLocationID           int32         \n",
      " 8   payment_type           int64         \n",
      " 9   fare_amount            float64       \n",
      " 10  extra                  float64       \n",
      " 11  mta_tax                float64       \n",
      " 12  tip_amount             float64       \n",
      " 13  tolls_amount           float64       \n",
      " 14  improvement_surcharge  float64       \n",
      " 15  total_amount           float64       \n",
      " 16  congestion_surcharge   float64       \n",
      " 17  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int32(3), int64(1)\n",
      "memory usage: 5.1 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-01 00:02:40</td>\n",
       "      <td>2024-04-01 00:30:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>29.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.25</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01 00:41:12</td>\n",
       "      <td>2024-04-01 00:55:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01 00:48:42</td>\n",
       "      <td>2024-04-01 01:05:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01 00:56:02</td>\n",
       "      <td>2024-04-01 01:05:09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-01 00:08:32</td>\n",
       "      <td>2024-04-01 00:10:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2024-04-01 00:02:40   2024-04-01 00:30:42              0.0   \n",
       "1         2  2024-04-01 00:41:12   2024-04-01 00:55:29              1.0   \n",
       "2         2  2024-04-01 00:48:42   2024-04-01 01:05:30              1.0   \n",
       "3         2  2024-04-01 00:56:02   2024-04-01 01:05:09              1.0   \n",
       "4         1  2024-04-01 00:08:32   2024-04-01 00:10:24              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID  PULocationID  DOLocationID  payment_type  \\\n",
       "0           5.20         1.0           161             7             1   \n",
       "1           5.60         1.0           264           264             1   \n",
       "2           3.55         1.0           186           236             1   \n",
       "3           1.06         1.0           137           164             2   \n",
       "4           0.70         1.0           236           263             1   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0         29.6    3.5      0.5        8.65           0.0   \n",
       "1         25.4    1.0      0.5       10.00           0.0   \n",
       "2         20.5    1.0      0.5        5.10           0.0   \n",
       "3         10.0    1.0      0.5        0.00           0.0   \n",
       "4          5.1    3.5      0.5        2.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         43.25                   2.5          0.0  \n",
       "1                    1.0         37.90                   0.0          0.0  \n",
       "2                    1.0         30.60                   2.5          0.0  \n",
       "3                    1.0         15.00                   2.5          0.0  \n",
       "4                    1.0         12.10                   2.5          0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df.drop(columns=['store_and_fwd_flag'], inplace=True)\n",
    "\n",
    "taxi_df.info()\n",
    "taxi_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.replace('NULL', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_df.replace('NULL', np.nan, inplace=True)\n",
    "collisions_df.drop(columns=['location'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91264 entries, 200490 to 291753\n",
      "Data columns (total 20 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   crash_date                     91264 non-null  datetime64[ns]\n",
      " 1   crash_time                     91264 non-null  object        \n",
      " 2   latitude                       84262 non-null  float64       \n",
      " 3   longitude                      84262 non-null  float64       \n",
      " 4   location                       84262 non-null  object        \n",
      " 5   on_street_name                 65077 non-null  object        \n",
      " 6   number_of_persons_injured      91264 non-null  int64         \n",
      " 7   number_of_persons_killed       91264 non-null  int64         \n",
      " 8   number_of_pedestrians_injured  91264 non-null  int64         \n",
      " 9   number_of_pedestrians_killed   91264 non-null  int64         \n",
      " 10  number_of_cyclist_injured      91264 non-null  int64         \n",
      " 11  number_of_cyclist_killed       91264 non-null  int64         \n",
      " 12  number_of_motorist_injured     91264 non-null  int64         \n",
      " 13  number_of_motorist_killed      91264 non-null  int64         \n",
      " 14  contributing_factor_vehicle_1  90586 non-null  object        \n",
      " 15  collision_id                   91264 non-null  int64         \n",
      " 16  borough                        65101 non-null  object        \n",
      " 17  zip_code                       65081 non-null  float64       \n",
      " 18  cross_street_name              26187 non-null  object        \n",
      " 19  off_street_name                46722 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(9), object(7)\n",
      "memory usage: 14.6+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43931/2509772436.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  collisions_df['contributing_factor_vehicle_1'].replace('Unspecified', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cols = ['crash_date', 'crash_time', 'latitude', 'longitude', 'location',\n",
    "       'on_street_name', 'number_of_persons_injured',\n",
    "       'number_of_persons_killed', 'number_of_pedestrians_injured',\n",
    "       'number_of_pedestrians_killed', 'number_of_cyclist_injured',\n",
    "       'number_of_cyclist_killed', 'number_of_motorist_injured',\n",
    "       'number_of_motorist_killed', 'contributing_factor_vehicle_1', 'collision_id','borough', 'zip_code',\n",
    "       'cross_street_name', 'off_street_name']\n",
    "collisions_df = collisions_df[cols]\n",
    "collisions_df.info()\n",
    "collisions_df.head()\n",
    "\n",
    "# Replace 'Unspecified' in 'contributing_factor_vehicle_1' with NaN\n",
    "collisions_df['contributing_factor_vehicle_1'].replace('Unspecified', np.nan, inplace=True)\n",
    "\n",
    "# Drop rows where 'latitude' or 'longitude' are missing\n",
    "collisions_df.dropna(subset=['latitude', 'longitude'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crash_date: 84262 non-null values, 321 unique values\n",
      " → Column is not purely numeric.\n",
      " → crash_date has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "crash_time: 84262 non-null values, 1440 unique values\n",
      " → Column is not purely numeric.\n",
      " → crash_time has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "location: 84262 non-null values, 40961 unique values\n",
      " → Column is not purely numeric.\n",
      " → location has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "on_street_name: 58601 non-null values, 5179 unique values\n",
      " → Column is not purely numeric.\n",
      " → on_street_name has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "contributing_factor_vehicle_1: 62351 non-null values, 54 unique values\n",
      " → Column is not purely numeric.\n",
      " → contributing_factor_vehicle_1 has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "borough: 64358 non-null values, 5 unique values\n",
      " → Column is not purely numeric.\n",
      " → borough has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "cross_street_name: 25661 non-null values, 18027 unique values\n",
      " → Column is not purely numeric.\n",
      " → cross_street_name has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n",
      "off_street_name: 44293 non-null values, 5974 unique values\n",
      " → Column is not purely numeric.\n",
      " → off_street_name has duplicate values and could be normalized.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = collisions_df\n",
    "for col in df.columns:\n",
    "    non_null_count = df[col].notnull().sum()\n",
    "    unique_count = df[col].nunique(dropna=True)\n",
    "    is_numeric = pd.api.types.is_numeric_dtype(df[col])\n",
    "\n",
    "    # Skip numeric columns\n",
    "    if is_numeric:\n",
    "        continue\n",
    "\n",
    "    # Print only if there are duplicate values (i.e., normalization candidates)\n",
    "    if unique_count < non_null_count:\n",
    "        print(f\"{col}: {non_null_count} non-null values, {unique_count} unique values\")\n",
    "        print(\" → Column is not purely numeric.\")\n",
    "        print(f\" → {col} has duplicate values and could be normalized.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Create the lookup tables with IDs\n",
    "def create_lookup_table(df, column_name, new_column_name):\n",
    "    lookup_df = df[[column_name]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    lookup_df.insert(0, f\"{new_column_name}_id\", range(1, len(lookup_df) + 1))\n",
    "    return lookup_df\n",
    "\n",
    "contributing_factor_lut = create_lookup_table(collisions_df, 'contributing_factor_vehicle_1', 'contributing_factor')\n",
    "borough_lut = create_lookup_table(collisions_df, 'borough', 'borough')\n",
    "cross_street_lut = create_lookup_table(collisions_df, 'cross_street_name', 'cross_street')\n",
    "off_street_lut = create_lookup_table(collisions_df, 'off_street_name', 'off_street')\n",
    "\n",
    "# 2. Map the original columns to their IDs\n",
    "collisions_df = collisions_df.merge(contributing_factor_lut, how='left', left_on='contributing_factor_vehicle_1', right_on='contributing_factor_vehicle_1')\n",
    "collisions_df = collisions_df.merge(borough_lut, how='left', left_on='borough', right_on='borough')\n",
    "collisions_df = collisions_df.merge(cross_street_lut, how='left', left_on='cross_street_name', right_on='cross_street_name')\n",
    "collisions_df = collisions_df.merge(off_street_lut, how='left', left_on='off_street_name', right_on='off_street_name')\n",
    "\n",
    "# 3. Optional: Drop original text columns and rename *_id columns\n",
    "collisions_df = collisions_df.drop(columns=[\n",
    "    'contributing_factor_vehicle_1',\n",
    "    'borough',\n",
    "    'cross_street_name',\n",
    "    'off_street_name'\n",
    "])\n",
    "\n",
    "collisions_df = collisions_df.rename(columns={\n",
    "    'contributing_factor_id': 'contributing_factor_vehicle_1_id',\n",
    "    'borough_id': 'borough_id',\n",
    "    'cross_street_id': 'cross_street_name_id',\n",
    "    'off_street_id': 'off_street_name_id'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributing_factor_lut\n",
    "borough_lut\n",
    "cross_street_lut\n",
    "off_street_lut\n",
    "collisions_df\n",
    "taxi_df\n",
    "geometry_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to PostgreSQL RDS instance successfully!\n",
      "Database version: ('PostgreSQL 17.2 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "RDS_HOST = os.getenv(\"DB_HOST\")\n",
    "RDS_PORT = os.getenv(\"DB_PORT\")\n",
    "RDS_USER = os.getenv(\"DB_USER\")\n",
    "RDS_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "RDS_DB = os.getenv(\"DB_NAME\")\n",
    "\n",
    "try:\n",
    "    # Establish PostgreSQL connection\n",
    "    conn = psycopg2.connect(\n",
    "        host=RDS_HOST,\n",
    "        user=RDS_USER,\n",
    "        password=RDS_PASSWORD,\n",
    "        dbname=RDS_DB,\n",
    "        port=RDS_PORT,\n",
    "        sslmode=\"require\"  \n",
    "    )\n",
    "    print(\"✅ Connected to PostgreSQL RDS instance successfully!\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a test query\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    version = cursor.fetchone()\n",
    "    print(\"Database version:\", version)\n",
    "\n",
    "    # Close connection\n",
    "    # cursor.close()\n",
    "    # conn.close()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error connecting to RDS:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>number_of_persons_injured</th>\n",
       "      <th>number_of_persons_killed</th>\n",
       "      <th>number_of_pedestrians_injured</th>\n",
       "      <th>number_of_pedestrians_killed</th>\n",
       "      <th>number_of_cyclist_injured</th>\n",
       "      <th>number_of_cyclist_killed</th>\n",
       "      <th>number_of_motorist_injured</th>\n",
       "      <th>number_of_motorist_killed</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>contributing_factor_vehicle_1_id</th>\n",
       "      <th>borough_id</th>\n",
       "      <th>cross_street_name_id</th>\n",
       "      <th>off_street_name_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>17:07</td>\n",
       "      <td>40.665657</td>\n",
       "      <td>-73.888084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4702082</td>\n",
       "      <td>11207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>10:00</td>\n",
       "      <td>40.730442</td>\n",
       "      <td>-73.913670</td>\n",
       "      <td>LONG ISLAND EXPRESSWAY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4691881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>21:56</td>\n",
       "      <td>40.666430</td>\n",
       "      <td>-73.882835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4692079</td>\n",
       "      <td>11207.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>6:00</td>\n",
       "      <td>40.685920</td>\n",
       "      <td>-73.846924</td>\n",
       "      <td>97 AVENUE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4691952</td>\n",
       "      <td>11416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>5:57</td>\n",
       "      <td>40.672382</td>\n",
       "      <td>-73.785740</td>\n",
       "      <td>BAISLEY BOULEVARD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4691606</td>\n",
       "      <td>11434.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  crash_date crash_time   latitude  longitude          on_street_name  \\\n",
       "0 2024-01-01      17:07  40.665657 -73.888084                     NaN   \n",
       "1 2024-01-01      10:00  40.730442 -73.913670  LONG ISLAND EXPRESSWAY   \n",
       "2 2024-01-01      21:56  40.666430 -73.882835                     NaN   \n",
       "3 2024-01-01       6:00  40.685920 -73.846924               97 AVENUE   \n",
       "4 2024-01-01       5:57  40.672382 -73.785740       BAISLEY BOULEVARD   \n",
       "\n",
       "   number_of_persons_injured  number_of_persons_killed  \\\n",
       "0                          0                         0   \n",
       "1                          1                         0   \n",
       "2                          2                         0   \n",
       "3                          0                         0   \n",
       "4                          1                         0   \n",
       "\n",
       "   number_of_pedestrians_injured  number_of_pedestrians_killed  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   number_of_cyclist_injured  number_of_cyclist_killed  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   number_of_motorist_injured  number_of_motorist_killed  collision_id  \\\n",
       "0                           0                          0       4702082   \n",
       "1                           1                          0       4691881   \n",
       "2                           2                          0       4692079   \n",
       "3                           0                          0       4691952   \n",
       "4                           0                          0       4691606   \n",
       "\n",
       "   zip_code  contributing_factor_vehicle_1_id  borough_id  \\\n",
       "0   11207.0                               NaN         1.0   \n",
       "1       NaN                               1.0         NaN   \n",
       "2   11207.0                               1.0         1.0   \n",
       "3   11416.0                               NaN         2.0   \n",
       "4   11434.0                               2.0         2.0   \n",
       "\n",
       "   cross_street_name_id  off_street_name_id  \n",
       "0                   1.0                 NaN  \n",
       "1                   NaN                 NaN  \n",
       "2                   2.0                 NaN  \n",
       "3                   NaN                 1.0  \n",
       "4                   NaN                 2.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_from_df(df, table_name, cursor):\n",
    "    # Generate column definitions\n",
    "    columns = []\n",
    "    for col_name, dtype in zip(df.columns, df.dtypes):\n",
    "        if 'int' in str(dtype):\n",
    "            col_type = 'INTEGER'\n",
    "        elif 'float' in str(dtype):\n",
    "            col_type = 'NUMERIC'\n",
    "        elif 'datetime' in str(dtype):\n",
    "            col_type = 'TIMESTAMP'\n",
    "        elif 'bool' in str(dtype):\n",
    "            col_type = 'BOOLEAN'\n",
    "        else:\n",
    "            col_type = 'TEXT'\n",
    "        \n",
    "        columns.append(f'\"{col_name}\" {col_type}')\n",
    "    \n",
    "    # Create table\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns)})\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Created table {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_df_to_postgres(df, table_name, cursor):\n",
    "    from io import StringIO\n",
    "    import csv  # Import csv for quoting options\n",
    "\n",
    "    # Create a buffer\n",
    "    buffer = StringIO()\n",
    "\n",
    "    # Write the DataFrame to the buffer\n",
    "    df.to_csv(buffer, index=False, header=False, na_rep='', quoting=csv.QUOTE_MINIMAL)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        # Use COPY command for fast data loading\n",
    "        column_list = ','.join([f'\"{col}\"' for col in df.columns])\n",
    "        cursor.copy_expert(\n",
    "            f\"COPY {table_name} ({column_list}) FROM STDIN WITH CSV NULL ''\",\n",
    "            buffer\n",
    "        )\n",
    "        print(f\"Uploaded {len(df)} rows to {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing contributing_factor_lut with 54 rows...\n",
      "Created table contributing_factor_lut\n",
      "Uploading chunk 1/1 (0 to 54 rows)\n",
      "Uploaded 54 rows to contributing_factor_lut\n",
      "🔄 Processing borough_lut with 5 rows...\n",
      "Created table borough_lut\n",
      "Uploading chunk 1/1 (0 to 5 rows)\n",
      "Uploaded 5 rows to borough_lut\n",
      "🔄 Processing cross_street_lut with 18027 rows...\n",
      "Created table cross_street_lut\n",
      "Uploading chunk 1/1 (0 to 18027 rows)\n",
      "Uploaded 18027 rows to cross_street_lut\n",
      "🔄 Processing off_street_lut with 5974 rows...\n",
      "Created table off_street_lut\n",
      "Uploading chunk 1/1 (0 to 5974 rows)\n",
      "Uploaded 5974 rows to off_street_lut\n",
      "🔄 Processing collisions_df with 84262 rows...\n",
      "Created table collisions_df\n",
      "Uploading chunk 1/2 (0 to 50000 rows)\n",
      "Uploaded 50000 rows to collisions_df\n",
      "Uploading chunk 2/2 (50000 to 84262 rows)\n",
      "Uploaded 34262 rows to collisions_df\n",
      "🔄 Processing taxi_df with 41169720 rows...\n",
      "Created table taxi_df\n",
      "Uploading chunk 1/824 (0 to 50000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 2/824 (50000 to 100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 3/824 (100000 to 150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 4/824 (150000 to 200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 5/824 (200000 to 250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 6/824 (250000 to 300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 7/824 (300000 to 350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 8/824 (350000 to 400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 9/824 (400000 to 450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 10/824 (450000 to 500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 11/824 (500000 to 550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 12/824 (550000 to 600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 13/824 (600000 to 650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 14/824 (650000 to 700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 15/824 (700000 to 750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 16/824 (750000 to 800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 17/824 (800000 to 850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 18/824 (850000 to 900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 19/824 (900000 to 950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 20/824 (950000 to 1000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 21/824 (1000000 to 1050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 22/824 (1050000 to 1100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 23/824 (1100000 to 1150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 24/824 (1150000 to 1200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 25/824 (1200000 to 1250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 26/824 (1250000 to 1300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 27/824 (1300000 to 1350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 28/824 (1350000 to 1400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 29/824 (1400000 to 1450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 30/824 (1450000 to 1500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 31/824 (1500000 to 1550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 32/824 (1550000 to 1600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 33/824 (1600000 to 1650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 34/824 (1650000 to 1700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 35/824 (1700000 to 1750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 36/824 (1750000 to 1800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 37/824 (1800000 to 1850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 38/824 (1850000 to 1900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 39/824 (1900000 to 1950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 40/824 (1950000 to 2000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 41/824 (2000000 to 2050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 42/824 (2050000 to 2100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 43/824 (2100000 to 2150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 44/824 (2150000 to 2200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 45/824 (2200000 to 2250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 46/824 (2250000 to 2300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 47/824 (2300000 to 2350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 48/824 (2350000 to 2400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 49/824 (2400000 to 2450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 50/824 (2450000 to 2500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 51/824 (2500000 to 2550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 52/824 (2550000 to 2600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 53/824 (2600000 to 2650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 54/824 (2650000 to 2700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 55/824 (2700000 to 2750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 56/824 (2750000 to 2800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 57/824 (2800000 to 2850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 58/824 (2850000 to 2900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 59/824 (2900000 to 2950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 60/824 (2950000 to 3000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 61/824 (3000000 to 3050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 62/824 (3050000 to 3100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 63/824 (3100000 to 3150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 64/824 (3150000 to 3200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 65/824 (3200000 to 3250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 66/824 (3250000 to 3300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 67/824 (3300000 to 3350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 68/824 (3350000 to 3400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 69/824 (3400000 to 3450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 70/824 (3450000 to 3500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 71/824 (3500000 to 3550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 72/824 (3550000 to 3600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 73/824 (3600000 to 3650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 74/824 (3650000 to 3700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 75/824 (3700000 to 3750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 76/824 (3750000 to 3800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 77/824 (3800000 to 3850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 78/824 (3850000 to 3900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 79/824 (3900000 to 3950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 80/824 (3950000 to 4000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 81/824 (4000000 to 4050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 82/824 (4050000 to 4100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 83/824 (4100000 to 4150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 84/824 (4150000 to 4200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 85/824 (4200000 to 4250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 86/824 (4250000 to 4300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 87/824 (4300000 to 4350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 88/824 (4350000 to 4400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 89/824 (4400000 to 4450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 90/824 (4450000 to 4500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 91/824 (4500000 to 4550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 92/824 (4550000 to 4600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 93/824 (4600000 to 4650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 94/824 (4650000 to 4700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 95/824 (4700000 to 4750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 96/824 (4750000 to 4800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 97/824 (4800000 to 4850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 98/824 (4850000 to 4900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 99/824 (4900000 to 4950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 100/824 (4950000 to 5000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 101/824 (5000000 to 5050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 102/824 (5050000 to 5100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 103/824 (5100000 to 5150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 104/824 (5150000 to 5200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 105/824 (5200000 to 5250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 106/824 (5250000 to 5300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 107/824 (5300000 to 5350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 108/824 (5350000 to 5400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 109/824 (5400000 to 5450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 110/824 (5450000 to 5500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 111/824 (5500000 to 5550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 112/824 (5550000 to 5600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 113/824 (5600000 to 5650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 114/824 (5650000 to 5700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 115/824 (5700000 to 5750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 116/824 (5750000 to 5800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 117/824 (5800000 to 5850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 118/824 (5850000 to 5900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 119/824 (5900000 to 5950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 120/824 (5950000 to 6000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 121/824 (6000000 to 6050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 122/824 (6050000 to 6100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 123/824 (6100000 to 6150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 124/824 (6150000 to 6200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 125/824 (6200000 to 6250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 126/824 (6250000 to 6300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 127/824 (6300000 to 6350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 128/824 (6350000 to 6400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 129/824 (6400000 to 6450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 130/824 (6450000 to 6500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 131/824 (6500000 to 6550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 132/824 (6550000 to 6600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 133/824 (6600000 to 6650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 134/824 (6650000 to 6700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 135/824 (6700000 to 6750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 136/824 (6750000 to 6800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 137/824 (6800000 to 6850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 138/824 (6850000 to 6900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 139/824 (6900000 to 6950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 140/824 (6950000 to 7000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 141/824 (7000000 to 7050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 142/824 (7050000 to 7100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 143/824 (7100000 to 7150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 144/824 (7150000 to 7200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 145/824 (7200000 to 7250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 146/824 (7250000 to 7300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 147/824 (7300000 to 7350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 148/824 (7350000 to 7400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 149/824 (7400000 to 7450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 150/824 (7450000 to 7500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 151/824 (7500000 to 7550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 152/824 (7550000 to 7600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 153/824 (7600000 to 7650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 154/824 (7650000 to 7700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 155/824 (7700000 to 7750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 156/824 (7750000 to 7800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 157/824 (7800000 to 7850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 158/824 (7850000 to 7900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 159/824 (7900000 to 7950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 160/824 (7950000 to 8000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 161/824 (8000000 to 8050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 162/824 (8050000 to 8100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 163/824 (8100000 to 8150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 164/824 (8150000 to 8200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 165/824 (8200000 to 8250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 166/824 (8250000 to 8300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 167/824 (8300000 to 8350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 168/824 (8350000 to 8400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 169/824 (8400000 to 8450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 170/824 (8450000 to 8500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 171/824 (8500000 to 8550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 172/824 (8550000 to 8600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 173/824 (8600000 to 8650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 174/824 (8650000 to 8700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 175/824 (8700000 to 8750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 176/824 (8750000 to 8800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 177/824 (8800000 to 8850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 178/824 (8850000 to 8900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 179/824 (8900000 to 8950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 180/824 (8950000 to 9000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 181/824 (9000000 to 9050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 182/824 (9050000 to 9100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 183/824 (9100000 to 9150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 184/824 (9150000 to 9200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 185/824 (9200000 to 9250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 186/824 (9250000 to 9300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 187/824 (9300000 to 9350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 188/824 (9350000 to 9400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 189/824 (9400000 to 9450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 190/824 (9450000 to 9500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 191/824 (9500000 to 9550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 192/824 (9550000 to 9600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 193/824 (9600000 to 9650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 194/824 (9650000 to 9700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 195/824 (9700000 to 9750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 196/824 (9750000 to 9800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 197/824 (9800000 to 9850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 198/824 (9850000 to 9900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 199/824 (9900000 to 9950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 200/824 (9950000 to 10000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 201/824 (10000000 to 10050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 202/824 (10050000 to 10100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 203/824 (10100000 to 10150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 204/824 (10150000 to 10200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 205/824 (10200000 to 10250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 206/824 (10250000 to 10300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 207/824 (10300000 to 10350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 208/824 (10350000 to 10400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 209/824 (10400000 to 10450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 210/824 (10450000 to 10500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 211/824 (10500000 to 10550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 212/824 (10550000 to 10600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 213/824 (10600000 to 10650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 214/824 (10650000 to 10700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 215/824 (10700000 to 10750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 216/824 (10750000 to 10800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 217/824 (10800000 to 10850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 218/824 (10850000 to 10900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 219/824 (10900000 to 10950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 220/824 (10950000 to 11000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 221/824 (11000000 to 11050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 222/824 (11050000 to 11100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 223/824 (11100000 to 11150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 224/824 (11150000 to 11200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 225/824 (11200000 to 11250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 226/824 (11250000 to 11300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 227/824 (11300000 to 11350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 228/824 (11350000 to 11400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 229/824 (11400000 to 11450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 230/824 (11450000 to 11500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 231/824 (11500000 to 11550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 232/824 (11550000 to 11600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 233/824 (11600000 to 11650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 234/824 (11650000 to 11700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 235/824 (11700000 to 11750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 236/824 (11750000 to 11800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 237/824 (11800000 to 11850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 238/824 (11850000 to 11900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 239/824 (11900000 to 11950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 240/824 (11950000 to 12000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 241/824 (12000000 to 12050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 242/824 (12050000 to 12100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 243/824 (12100000 to 12150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 244/824 (12150000 to 12200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 245/824 (12200000 to 12250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 246/824 (12250000 to 12300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 247/824 (12300000 to 12350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 248/824 (12350000 to 12400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 249/824 (12400000 to 12450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 250/824 (12450000 to 12500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 251/824 (12500000 to 12550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 252/824 (12550000 to 12600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 253/824 (12600000 to 12650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 254/824 (12650000 to 12700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 255/824 (12700000 to 12750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 256/824 (12750000 to 12800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 257/824 (12800000 to 12850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 258/824 (12850000 to 12900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 259/824 (12900000 to 12950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 260/824 (12950000 to 13000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 261/824 (13000000 to 13050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 262/824 (13050000 to 13100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 263/824 (13100000 to 13150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 264/824 (13150000 to 13200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 265/824 (13200000 to 13250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 266/824 (13250000 to 13300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 267/824 (13300000 to 13350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 268/824 (13350000 to 13400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 269/824 (13400000 to 13450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 270/824 (13450000 to 13500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 271/824 (13500000 to 13550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 272/824 (13550000 to 13600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 273/824 (13600000 to 13650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 274/824 (13650000 to 13700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 275/824 (13700000 to 13750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 276/824 (13750000 to 13800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 277/824 (13800000 to 13850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 278/824 (13850000 to 13900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 279/824 (13900000 to 13950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 280/824 (13950000 to 14000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 281/824 (14000000 to 14050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 282/824 (14050000 to 14100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 283/824 (14100000 to 14150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 284/824 (14150000 to 14200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 285/824 (14200000 to 14250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 286/824 (14250000 to 14300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 287/824 (14300000 to 14350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 288/824 (14350000 to 14400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 289/824 (14400000 to 14450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 290/824 (14450000 to 14500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 291/824 (14500000 to 14550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 292/824 (14550000 to 14600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 293/824 (14600000 to 14650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 294/824 (14650000 to 14700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 295/824 (14700000 to 14750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 296/824 (14750000 to 14800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 297/824 (14800000 to 14850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 298/824 (14850000 to 14900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 299/824 (14900000 to 14950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 300/824 (14950000 to 15000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 301/824 (15000000 to 15050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 302/824 (15050000 to 15100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 303/824 (15100000 to 15150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 304/824 (15150000 to 15200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 305/824 (15200000 to 15250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 306/824 (15250000 to 15300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 307/824 (15300000 to 15350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 308/824 (15350000 to 15400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 309/824 (15400000 to 15450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 310/824 (15450000 to 15500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 311/824 (15500000 to 15550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 312/824 (15550000 to 15600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 313/824 (15600000 to 15650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 314/824 (15650000 to 15700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 315/824 (15700000 to 15750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 316/824 (15750000 to 15800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 317/824 (15800000 to 15850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 318/824 (15850000 to 15900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 319/824 (15900000 to 15950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 320/824 (15950000 to 16000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 321/824 (16000000 to 16050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 322/824 (16050000 to 16100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 323/824 (16100000 to 16150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 324/824 (16150000 to 16200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 325/824 (16200000 to 16250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 326/824 (16250000 to 16300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 327/824 (16300000 to 16350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 328/824 (16350000 to 16400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 329/824 (16400000 to 16450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 330/824 (16450000 to 16500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 331/824 (16500000 to 16550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 332/824 (16550000 to 16600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 333/824 (16600000 to 16650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 334/824 (16650000 to 16700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 335/824 (16700000 to 16750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 336/824 (16750000 to 16800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 337/824 (16800000 to 16850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 338/824 (16850000 to 16900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 339/824 (16900000 to 16950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 340/824 (16950000 to 17000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 341/824 (17000000 to 17050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 342/824 (17050000 to 17100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 343/824 (17100000 to 17150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 344/824 (17150000 to 17200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 345/824 (17200000 to 17250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 346/824 (17250000 to 17300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 347/824 (17300000 to 17350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 348/824 (17350000 to 17400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 349/824 (17400000 to 17450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 350/824 (17450000 to 17500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 351/824 (17500000 to 17550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 352/824 (17550000 to 17600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 353/824 (17600000 to 17650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 354/824 (17650000 to 17700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 355/824 (17700000 to 17750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 356/824 (17750000 to 17800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 357/824 (17800000 to 17850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 358/824 (17850000 to 17900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 359/824 (17900000 to 17950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 360/824 (17950000 to 18000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 361/824 (18000000 to 18050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 362/824 (18050000 to 18100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 363/824 (18100000 to 18150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 364/824 (18150000 to 18200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 365/824 (18200000 to 18250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 366/824 (18250000 to 18300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 367/824 (18300000 to 18350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 368/824 (18350000 to 18400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 369/824 (18400000 to 18450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 370/824 (18450000 to 18500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 371/824 (18500000 to 18550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 372/824 (18550000 to 18600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 373/824 (18600000 to 18650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 374/824 (18650000 to 18700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 375/824 (18700000 to 18750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 376/824 (18750000 to 18800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 377/824 (18800000 to 18850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 378/824 (18850000 to 18900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 379/824 (18900000 to 18950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 380/824 (18950000 to 19000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 381/824 (19000000 to 19050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 382/824 (19050000 to 19100000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 383/824 (19100000 to 19150000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 384/824 (19150000 to 19200000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 385/824 (19200000 to 19250000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 386/824 (19250000 to 19300000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 387/824 (19300000 to 19350000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 388/824 (19350000 to 19400000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 389/824 (19400000 to 19450000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 390/824 (19450000 to 19500000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 391/824 (19500000 to 19550000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 392/824 (19550000 to 19600000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 393/824 (19600000 to 19650000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 394/824 (19650000 to 19700000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 395/824 (19700000 to 19750000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 396/824 (19750000 to 19800000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 397/824 (19800000 to 19850000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 398/824 (19850000 to 19900000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 399/824 (19900000 to 19950000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 400/824 (19950000 to 20000000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 401/824 (20000000 to 20050000 rows)\n",
      "Uploaded 50000 rows to taxi_df\n",
      "Uploading chunk 402/824 (20050000 to 20100000 rows)\n"
     ]
    }
   ],
   "source": [
    "# List of dataframes to upload\n",
    "dataframes = {\n",
    "    'contributing_factor_lut': contributing_factor_lut,\n",
    "    'borough_lut': borough_lut,\n",
    "    'cross_street_lut': cross_street_lut,\n",
    "    'off_street_lut': off_street_lut,\n",
    "    'collisions_df': collisions_df,\n",
    "    'taxi_df': taxi_df,\n",
    "    'geometry_df': geometry_df\n",
    "}\n",
    "\n",
    "# Process each dataframe\n",
    "for table_name, df in dataframes.items():\n",
    "    print(f\"🔄 Processing {table_name} with {len(df)} rows...\")\n",
    "    \n",
    "    # Create the table\n",
    "    create_table_from_df(df, table_name, cursor)\n",
    "    \n",
    "    # Process in chunks to handle large dataframes\n",
    "    chunk_size = 50000\n",
    "    total_chunks = (len(df) + chunk_size - 1) // chunk_size  # Ceiling division\n",
    "    \n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        chunk_num = i // chunk_size + 1\n",
    "        print(f\"Uploading chunk {chunk_num}/{total_chunks} ({i} to {min(i+chunk_size, len(df))} rows)\")\n",
    "        copy_df_to_postgres(chunk, table_name, cursor)\n",
    "        # Commit after each chunk to avoid long transactions\n",
    "        conn.commit()\n",
    "\n",
    "print(\"All data uploaded successfully!\")\n",
    "\n",
    "# Close connections\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtaxi_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables dropped successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop all tables in the public schema\n",
    "cursor.execute(\"\"\"\n",
    "    DO $$ \n",
    "    BEGIN\n",
    "        EXECUTE (\n",
    "            SELECT string_agg('DROP TABLE IF EXISTS \"' || table_name || '\" CASCADE;', ' ')\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema = 'public'\n",
    "        );\n",
    "    END $$;\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"All tables dropped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "contributing_factor_lut\n",
      "borough_lut\n",
      "cross_street_lut\n",
      "off_street_lut\n",
      "taxi_df\n",
      "collisions_df\n",
      "Number of rows in taxi_df: 20500000\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) AS row_count\n",
    "    FROM taxi_df\n",
    "\"\"\")\n",
    "row_count = cursor.fetchone()\n",
    "\n",
    "# Print the number of rows\n",
    "print(f\"Number of rows in taxi_df: {row_count[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows already uploaded: 20500000\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT COUNT(*) FROM taxi_df\")\n",
    "uploaded_rows = cursor.fetchone()[0]\n",
    "print(f\"Rows already uploaded: {uploaded_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunk 411 (20500000 to 20550000 rows)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'copy_df_to_postgres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m chunk_num \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m chunk_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39mchunk_size,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(taxi_df))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mcopy_df_to_postgres\u001b[49m(chunk, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxi_df\u001b[39m\u001b[38;5;124m'\u001b[39m, cursor)\n\u001b[1;32m      9\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()  \u001b[38;5;66;03m# Commit after each chunk\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy_df_to_postgres' is not defined"
     ]
    }
   ],
   "source": [
    "start_row = uploaded_rows  # Start from the last uploaded row\n",
    "chunk_size = 50000  # Adjust chunk size if needed\n",
    "\n",
    "for i in range(start_row, len(taxi_df), chunk_size):\n",
    "    chunk = taxi_df.iloc[i:i+chunk_size]\n",
    "    chunk_num = i // chunk_size + 1\n",
    "    print(f\"Uploading chunk {chunk_num} ({i} to {min(i+chunk_size, len(taxi_df))} rows)\")\n",
    "    copy_df_to_postgres(chunk, 'taxi_df', cursor)\n",
    "    conn.commit()  # Commit after each chunk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
